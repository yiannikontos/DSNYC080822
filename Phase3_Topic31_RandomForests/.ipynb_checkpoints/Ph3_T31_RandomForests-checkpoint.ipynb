{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Ensemble Learning: Bagging and Random Forests\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Feb 2022\n",
    "<p>Phase 3: Topic 31</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier,\\\n",
    "ExtraTreesClassifier, VotingClassifier, StackingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Kim-Jong-un after using decision tree: launch nukes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/kimjongun.jpg\" width = 700 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maybe better to make this a more democratic process with more perspectives on the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Other decision makers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<table><tr><td><img src=\"Images/mother_teresa.webp\" width=\"250\"/><br><center>Mother Theresa</center></td><td><img src=\"Images/sakharov.jpg\" width=\"200\"/><br><center>Andrei Sakharov</center></td><td><img src=\"Images/cat_press_button.gif\" width=\"300\"/><br><center>Nice kitty.</center></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This thinking applicable to all models:\n",
    "- particularly useful in the context of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Deficiencies of Decision Trees:\n",
    "- that ensemble learning can address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reminder of decision trees: \n",
    "- recursively make splits based on entropy or impurity\n",
    "- split on feature best increasing information gain\n",
    "- Keep splitting until leaf pure OR max depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dec_tree_partitioning.jpg\" width = 800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Tendency to overfit at large max depth.\n",
    "- High enough depth: will fit to training set perfectly.\n",
    "\n",
    "<img src = \"Images/dectree_perfectfit.png\" />\n",
    "<center> A perfect fit to the training set. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/decisiontree_classification_overfitting.png\"  />\n",
    "<center> Some more decision tree overfitting </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Too much **variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To avoid: reduce decision tree depth to limit variance.\n",
    "    \n",
    "But with decision tree, will easily end up underfitting.\n",
    "\n",
    "- Can increase depth again to get better:\n",
    "    - But very likely to learn a boundary that overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dectree_underfitting.png\" width = 400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias-variance problem is severe with Decision Tree models:\n",
    "- Very sensitive to tree depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A very nice visualization of this sensitivity on the regression task:\n",
    "<img src = \"Images/decision_tree_regression.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Decision trees not-robust**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Criterion is harsh: choose *single* feature that wins and split on that.\n",
    "- But many features may be important in a region and should be factored in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/tree_features.png\" />\n",
    "Both Culmen length and depth matter here. But split for each region considers only one or the other.\n",
    "\n",
    "- Doesn't reflect the way features are related to each other and collectively impact the target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Can we figure out a way in a split for a given subregion to factor in different features?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Depending on goal could be nice if modeling target-feature function:\n",
    "- without feature engineering.\n",
    "- without distributional assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another issue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recursion: after split on \"best\" feature, different subsets never talk to each other again.\n",
    "- But maybe other branches/regions: info influencing split/class assignment in given subregion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dec_tree_partitioning.jpg\" width =500/>\n",
    "<center>Choosing next split: black or orange?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Perhaps sampling/factoring in different regions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Increasing depth and number of splits:\n",
    "- Very quickly: small number of points in given sub-region\n",
    "- Feature decision very sensitive to points in specific region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points.png\" width = 200 />\n",
    "<center> Plausible small subregion with few points </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two possible choices (equivalent in terms of impurity):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt1.png\" width = 200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt2.png\" width = 200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Decision boundary instability: \n",
    "- small changes/fluctuations in data lead to very different decision surface locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt1_inst.png\" width =400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt2_inst.png\" width =400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to get around this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Don't want to rely too heavily on specific data points and their location:\n",
    "- Maybe introducing randomness in data point sampling in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Why am I using decision trees at all then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### But decision trees are blindingly fast.\n",
    "- Recursion on binary trees\n",
    "- Greedy criterion:\n",
    "    - always split on best feature at local node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Want to keep this speed and still use trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But also want to:\n",
    "- Sample other features when making splits\n",
    "- Sample other regions in feature-space when making decisions on class assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Learn from classifiers training on different realizations of the dataset:\n",
    "    - a set of given points has different weight/importance in each realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Way to create realization of dataset with different weights for data: \n",
    "- **Bagging (boostrap aggregation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/sample_bagging_only.png\" width = 600/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src = \"Images/sample_bagging_only.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The boostrap:\n",
    "\n",
    "- N samples in training set.\n",
    "- Randomly resample training set **with replacement** N times.\n",
    "- Resampled set also has N samples.\n",
    "\n",
    "A given point now has different weight/importance in each realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More explicitly: see training point reweighting under bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  1. ],\n",
       "       [ 3.1,  0. ],\n",
       "       [-2.5,  1. ],\n",
       "       [ 1. ,  0. ],\n",
       "       [-4. ,  1. ],\n",
       "       [ 0.5,  0. ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (feature, label) pairs\n",
    "train = np.array([(-1,1), (3.1, 0) , (-2.5, 1),\n",
    "         (1, 0), (-4, 1), (.5, 0)])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4. ,  1. ],\n",
       "       [-4. ,  1. ],\n",
       "       [ 0.5,  0. ],\n",
       "       [ 0.5,  0. ],\n",
       "       [-2.5,  1. ],\n",
       "       [ 1. ,  0. ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "idx_resampled =choice(range(len(train)), \n",
    "                      size = len(train),\n",
    "                       replace = True)\n",
    "train[idx_resampled]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Now use ensemble of trained models\n",
    "- Aggregate to make prediction on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/bagging_classifier.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the context of regression:\n",
    "- aggregation function is average of regressor trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/bagging_regressor.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The concept of bagging of estimators is **NOT** limited to trees:\n",
    "- can use any classifier or regressor and perform bagging procedures.\n",
    "- but mainly useful for local models like DecisionTree or KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To implement bagging classifier in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# if doing classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# if doing regression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll do classification:\n",
    "- Predict diabetes via health stats\n",
    "- Pima Indian diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df = pd.read_csv('Data/diabetes.csv')\n",
    "diab_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "diab_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate features and target\n",
    "- Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = diab_df.drop(columns = ['Outcome'])\n",
    "y = diab_df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now develop our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define the bagging classifier and put it into a pipeline. \n",
    "\n",
    "Then integrate into a grid search tuning on tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bag_class_decision = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 150)\n",
    "bag_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       bag_class_decision)])\n",
    "params = {'model__base_estimator__max_depth': np.arange(4,28,4)}\n",
    "cv = GridSearchCV(estimator = bag_pipe, param_grid = params, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Get best model and its balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__base_estimator__max_depth': 16}"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = cv.best_estimator_\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7607516147974163"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__base_estimator__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.760716</td>\n",
       "      <td>0.034896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.759201</td>\n",
       "      <td>0.022072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.750006</td>\n",
       "      <td>0.032788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.760752</td>\n",
       "      <td>0.031913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.748444</td>\n",
       "      <td>0.033286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>0.753106</td>\n",
       "      <td>0.033878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_model__base_estimator__max_depth  mean_test_score  std_test_score\n",
       "0                                      4         0.760716        0.034896\n",
       "1                                      8         0.759201        0.022072\n",
       "2                                     12         0.750006        0.032788\n",
       "3                                     16         0.760752        0.031913\n",
       "4                                     20         0.748444        0.033286\n",
       "5                                     24         0.753106        0.033878"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.cv_results_)[['param_model__base_estimator__max_depth', 'mean_test_score', 'std_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fit the best model. Get predictions and report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81        76\n",
      "           1       0.64      0.62      0.63        40\n",
      "\n",
      "    accuracy                           0.75       116\n",
      "   macro avg       0.72      0.72      0.72       116\n",
      "weighted avg       0.75      0.75      0.75       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Is bagging better than baseline decision tree over the same range of tree depths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "simpletree_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       DecisionTreeClassifier())]) \n",
    "\n",
    "params = {'model__max_depth': np.arange(4,28,4)}\n",
    "\n",
    "cvtree = GridSearchCV(estimator = simpletree_pipe, param_grid = params, cv = 5)\n",
    "\n",
    "cvtree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 4}"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_simplemodel = cvtree.best_estimator_\n",
    "cvtree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499941280093951"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvtree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78        76\n",
      "           1       0.59      0.68      0.63        40\n",
      "\n",
      "    accuracy                           0.72       116\n",
      "   macro avg       0.70      0.71      0.70       116\n",
      "weighted avg       0.74      0.72      0.73       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_simplemodel.fit(X_train, y_train)\n",
    "y_pred_simple = best_simplemodel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A bit worse on the precision/recall for all classes -- especially positive class. \n",
    "- In many cases improvements on bagging alone will not be so significant.\n",
    "- Sample bagging alone usually not enough to capture feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reason: \n",
    "- boostrapped samples are still highly correlated with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Final ingredient (first set of strategies)\n",
    "\n",
    "- Effectively factor in other features when making splits\n",
    "- Sample other regions in feature-space when making decisions on class assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can effectively do this by considering only a random subset of features to split on at each node\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Result: each tree may partition feature space in appreciably different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/rf_splitting.png\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Overall effect of this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/indtree.gif\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each decision tree can learn different important features to make splits on throughout feature space.\n",
    "- Each tree can assign a given feature region to different classes based on its splits.\n",
    "\n",
    "Individual trees making errors but **different** errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/rfplot.gif\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Aggregating smooths large fluctuations of class assignments from individual trees out.\n",
    "- Due to feature subset sampling: can learn more complex boundaries: smoothens these.\n",
    "- Can also get probability of class assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       RandomForestClassifier(n_estimators = 100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_rf_pred = rf_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82        76\n",
      "           1       0.66      0.68      0.67        40\n",
      "\n",
      "    accuracy                           0.77       116\n",
      "   macro avg       0.74      0.75      0.74       116\n",
      "weighted avg       0.77      0.77      0.77       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Better than bagging and base Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Should tune model: understand relevant hyperparameters\n",
    "- understand parameters of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- n_estimators: number of trees in forest (very important):\n",
    "    - optimal will depend on dataset size. But 50-250 is good starting tuning range.\n",
    "- max_features: number of features to randomly sample at each node for evaluating split criterion.\n",
    "    - good starting value (also default) is $\\sqrt{M}$ where $M$ is number of features. (theoretical justification for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- max_depth: tree depth\n",
    "    - due to randomizing and averaging: random forest not as sensitive to this as DecisionTree.\n",
    "    - default is None. Trains tree to leaf purity. Typically don't touch this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- min_sample_leaf: minimum number of samples required to be at a leaf node.\n",
    "    - Default is 1 but having larger numbers can mean averaging effect from leaf\n",
    "    - Higher values can have a regularizing effect.\n",
    "    - Typically tune from 1-100 (depends on size of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For min sample leaf criterion: cuts out different portions of tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/min_sample_leaf.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can also change objective functions:\n",
    "- Gini\n",
    "- entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Grid Search CV on our random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('model', RandomForestClassifier())]),\n",
       "             param_grid={'model__min_samples_leaf': [1, 3, 5, 7],\n",
       "                         'model__n_estimators': [50, 100, 200, 500]})"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {'model__n_estimators': [50, 100, 200, 500] ,\n",
    "             'model__min_samples_leaf': [1,3,5,7]}\n",
    "rf_cv = GridSearchCV(estimator = rf_pipe, param_grid = rf_params, cv = 5)\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699354081033472"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__min_samples_leaf': 3, 'model__n_estimators': 500}"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(min_samples_leaf=3, n_estimators=500))])"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model = rf_cv.best_estimator_\n",
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(min_samples_leaf=3, n_estimators=500))])"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84        76\n",
      "           1       0.69      0.72      0.71        40\n",
      "\n",
      "    accuracy                           0.79       116\n",
      "   macro avg       0.77      0.78      0.77       116\n",
      "weighted avg       0.80      0.79      0.79       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_rfcv_pred = best_rf_model.predict(X_test)\n",
    "print(classification_report(y_test,y_rfcv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK this is pretty decent. There is also another nice thing about random forests:\n",
    "\n",
    "Can see which features are most important in prediction:\n",
    "\n",
    "- .feature_importances_ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp = best_rf_model['model'].feature_importances_\n",
    "\n",
    "feat_imp_series = pd.Series(feat_imp, \n",
    "          index = X.columns).sort_values(\n",
    "    ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose                     0.299165\n",
       "BMI                         0.178571\n",
       "Age                         0.136588\n",
       "DiabetesPedigreeFunction    0.108263\n",
       "Pregnancies                 0.075907\n",
       "BloodPressure               0.071042\n",
       "Insulin                     0.066262\n",
       "SkinThickness               0.064203\n",
       "dtype: float64"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp_series.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Evaluates feature importance:\n",
    "- Determining for each tree how many times feature was used for splitting.\n",
    "- Counts up occurences across entire forest and weights features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Extremely Randomized Trees (Extra Trees)\n",
    "- Sometimes our variance problems are extreme.\n",
    "- Random forest taking way too long with too many estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Might want even one more randomization. \n",
    "- Instead of always choosing the *optimal* split at node:\n",
    "    - randomly sample feature space inside node. \n",
    "    - split on best information gain from random sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now **three** levels of randomization: \n",
    "- sampling of data\n",
    "- sampling of features\n",
    "- random selection of branching paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compare typical effects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/extraatrees_forest_iris.png\" width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Extra randomness makes ExtraTrees a softer classifier.\n",
    "- Very good for variance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's import it and do our magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(max_features='sqrt',\n",
    "                         max_samples=0.5,\n",
    "                         bootstrap=True,\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, max_features='sqrt', max_samples=0.5,\n",
       "                     random_state=1)"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it\n",
    "\n",
    "etc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71755725, 0.80916031, 0.76923077, 0.71538462, 0.77692308])"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation\n",
    "\n",
    "scores = cross_val_score(estimator=etc, X=X_train,\n",
    "               y=y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8189655172413793"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score on test\n",
    "\n",
    "etc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86        76\n",
      "           1       0.74      0.72      0.73        40\n",
      "\n",
      "    accuracy                           0.82       116\n",
      "   macro avg       0.80      0.80      0.80       116\n",
      "weighted avg       0.82      0.82      0.82       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_etc_pred = etc.predict(X_test)\n",
    "print(classification_report(y_test, y_etc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sometimes** the extra randomization can do even better.\n",
    "- When suffering from variance issues.\n",
    "- Also ExtraTrees is very very fast:\n",
    "    - doesn't spend too much time on finding optimal splits."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
